{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# هدف : کم و زیاد کردن نور و صدا در اوبونتو با حرکات دست\n",
    "## دست راست برای صدا  و دست چپ برای نور صفحه نمایش"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 19:48:41.951985: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-25 19:48:41.962493: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-25 19:48:41.975266: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-25 19:48:41.978696: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-25 19:48:41.988558: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-25 19:48:42.676311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import mediapipe as mp\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# نادیده گرفتن هشدار های کم اهمیت"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from google.protobuf import message as pb_message\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='google.protobuf.symbol_database')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# توابع مربوط به صدا"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def set_volume_increase(amount):\n",
    "    subprocess.run(['pactl', 'set-sink-volume', '@DEFAULT_SINK@', f'+{amount}%'])\n",
    "\n",
    "def set_volume_decrease(amount):\n",
    "    subprocess.run(['pactl', 'set-sink-volume', '@DEFAULT_SINK@', f'-{amount}%'])\n",
    "\n",
    "def set_volume(level):\n",
    "    subprocess.run(['pactl', 'set-sink-volume', '@DEFAULT_SINK@', f'{level}%'])\n",
    "\n",
    "def get_volume():\n",
    "    output = subprocess.check_output(['pactl', 'get-sink-volume', '@DEFAULT_SINK@']).decode('utf-8')\n",
    "    volume = output.split()[4].replace('%', '')\n",
    "    return int(volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# توابع مربوط به نور صفحه نمایش\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_current_brightness():\n",
    "    # مسیر فایل‌های سیستمی مرتبط با روشنایی\n",
    "    brightness_file = \"/sys/class/backlight/intel_backlight/brightness\"\n",
    "    max_brightness_file = \"/sys/class/backlight/intel_backlight/max_brightness\"\n",
    "\n",
    "    # خواندن مقدار فعلی روشنایی\n",
    "    with open(brightness_file, 'r') as f:\n",
    "        current_brightness = int(f.read().strip())\n",
    "\n",
    "    # خواندن حداکثر مقدار روشنایی\n",
    "    with open(max_brightness_file, 'r') as f:\n",
    "        max_brightness = int(f.read().strip())\n",
    "\n",
    "    # محاسبه درصد روشنایی فعلی\n",
    "    brightness_percentage = (current_brightness / max_brightness) * 100\n",
    "\n",
    "    return brightness_percentage\n",
    "\n",
    "# چاپ درصد روشنایی فعلی\n",
    "# current_brightness_percentage = get_current_brightness()\n",
    "# print(f\"Current brightness: {current_brightness_percentage:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "def set_brightness(level):\n",
    "    # اطمینان حاصل کنید که مقدار روشنایی بین 0 و 1 است\n",
    "    if level < 0 or level > 1:\n",
    "        raise ValueError(\"Brightness level must be between 0 and 1.\")\n",
    "    \n",
    "    # مسیر فایل تنظیم روشنایی\n",
    "    brightness_file = \"/sys/class/backlight/intel_backlight/brightness\"\n",
    "    max_brightness_file = \"/sys/class/backlight/intel_backlight/max_brightness\"\n",
    "\n",
    "    # خواندن حداکثر مقدار روشنایی\n",
    "    with open(max_brightness_file, 'r') as f:\n",
    "        max_brightness = int(f.read().strip())\n",
    "    \n",
    "    # محاسبه مقدار جدید روشنایی\n",
    "    new_brightness = int(max_brightness * level)\n",
    "\n",
    "    # استفاده از subprocess برای اجرای دستور با sudo\n",
    "    command = f\"echo {new_brightness} | sudo tee {brightness_file} > /dev/null\"\n",
    "    subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# تعریف رنگ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv تعریف رنگ‌ها برای استفاده در ترسیمات البته برعکس چون \n",
    "red = (0, 0, 255)\n",
    "green = (0, 255, 0)\n",
    "blue = (255, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724602723.901746   28390 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1724602723.903601   28794 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.1), renderer: Mesa Intel(R) Xe Graphics (TGL GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# 1-  Mediapipe راه‌اندازی مدل تشخیص دست از\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# 2- Mediapipe راه‌اندازی ابزارهای ترسیم از\n",
    "mp_drawing = mp.solutions.drawing_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1724602723.922244   28782 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1724602723.938968   28789 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# راه‌اندازی وبکم\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 3- پردازش فریم برای تشخیص دست‌ها\n",
    "    results = hands.process(frame_rgb)\n",
    "    \n",
    "    landmark_4 = []  # تعریف لیست برای نقطه شماره 4\n",
    "    landmark_8 = []  # تعریف لیست برای نقطه شماره 8\n",
    "    volume=get_volume()\n",
    "    brightness = get_current_brightness()\n",
    "    \n",
    "    # بررسی اگر دست‌ها تشخیص داده شدند\n",
    "    if results.multi_hand_landmarks:\n",
    "        # بررسی اگر دست راست بود\n",
    "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "            hand_label = handedness.classification[0].label\n",
    "            \n",
    "            for id, pos_id in enumerate(hand_landmarks.landmark): # id : شماره نقظه در انگشت ها | pos_id : مختصات نسبی در صفحه\n",
    "                \n",
    "                    # برای کار کردن با فاصله بین انگشتان\n",
    "                    h, w, c = frame.shape  # گرفتن ابعاد تصویر\n",
    "                    x, y = int(pos_id.x * w), int(pos_id.y * h)  # تبدیل مختصات نسبی به پیکسلی\n",
    "                    \n",
    "                    # landmark_list.append([id, x, y])\n",
    "\n",
    "                    # اگر نقطه شماره 4 (نوک انگشت شست) باشد، دایره‌ای رسم کن\n",
    "                    if id == 4:\n",
    "                        cv2.circle(frame, (x, y), 15, blue, -1)  # -1 یعنی دایره توپر باشد\n",
    "                        landmark_4.append([x,y])\n",
    "\n",
    "                    # اگر نقطه شماره 4 (نوک انگشت شست) باشد، دایره‌ای رسم کن\n",
    "                    if id == 8:\n",
    "                        cv2.circle(frame, (x, y), 15, blue, -1)  # -1 یعنی دایره توپر باشد\n",
    "                        landmark_8.append([x,y])\n",
    "                                        \n",
    "                    # محاسبه فاصله بین نقاط شماره 4 و 8\n",
    "                    if len(landmark_4) > 0 and len(landmark_8) > 0:\n",
    "                        x1, y1 = landmark_4[0]\n",
    "                        x2, y2 = landmark_8[0]\n",
    "                        distance_between_4_8 = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "                        # print(f\"Distance between points 4 and 8: {distance_between_4_8}\")\n",
    "                        \n",
    "\n",
    "            # بررسی اگر دست راست باشد\n",
    "            if hand_label == 'Right':  \n",
    "                \n",
    "                min_distance = 25\n",
    "                max_distance = 280\n",
    "                \n",
    "                min_sound = 0\n",
    "                max_sound = 100\n",
    "                \n",
    "                if distance_between_4_8 < min_distance:\n",
    "                    distance_between_4_8 = min_distance\n",
    "                elif distance_between_4_8 > max_distance:\n",
    "                    distance_between_4_8 = max_distance\n",
    "                        \n",
    "                volume = min_sound + (int((distance_between_4_8 - min_distance) * (max_sound - min_sound) / (max_distance - min_distance)))\n",
    "                # print(volume)\n",
    "                                    \n",
    "                # تنظیم صدا بر اساس محاسبه جدید\n",
    "                set_volume(volume)  # این خط را فعال کنید تا صدا بر اساس فاصله تنظیم شود\n",
    "                \n",
    "                # نوشتن اندازه صدا در لحظه\n",
    "                cv2.putText(frame, f'Volume: {volume}%', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                    \n",
    "            elif hand_label=='Left':\n",
    "                \n",
    "                # مقادیر حداقل و حداکثر فاصله\n",
    "                min_distance = 25  # جایگزین با مقدار واقعی حداقل فاصله\n",
    "                max_distance = 280  # جایگزین با مقدار واقعی حداکثر فاصله\n",
    "\n",
    "                min_brightness = 0.1\n",
    "                max_brightness = 1.0\n",
    "\n",
    "                # اطمینان از اینکه distance_between_4_8 در بازه‌ی مشخص است\n",
    "                if distance_between_4_8 < min_distance:\n",
    "                    distance_between_4_8 = min_distance\n",
    "                elif distance_between_4_8 > max_distance:\n",
    "                    distance_between_4_8 = max_distance\n",
    "\n",
    "                # محاسبه روشنایی بر اساس فاصله\n",
    "                brightness = min_brightness + (int(distance_between_4_8 - min_distance) * (max_brightness - min_brightness) / (max_distance - min_distance))\n",
    "                set_brightness(brightness)\n",
    "                cv2.putText(frame, f'Brightness: {brightness * 100:.0f}%', (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                \n",
    "            # رسم اتصالات و نقاط کلیدی دست\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "\n",
    "    # نمایش فریم پردازش شده\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    \n",
    "    # به‌دست آوردن زمان کنونی\n",
    "    current_time = datetime.now()\n",
    "    current_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    k = cv2.waitKey(1) & 0xFF \n",
    "    if k==27:    # برای خروج Esc کلید \n",
    "        break\n",
    "    \n",
    "    elif k== ord('q'): # q یا دکمه \n",
    "        break\n",
    "    \n",
    "    elif k == ord('s'):\n",
    "        filename = f'Data/Volume_Hand_Control{current_time}.jpg'\n",
    "        cv2.imwrite(filename,frame)\n",
    "        print(f\"Image saved as {filename}\")\n",
    "        \n",
    "# آزاد کردن منابع\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Data/Volume_Hand_Control_1.png'>\n",
    "<img src = 'Data/Volume_Hand_Control_2.png'>\n",
    "<img src = 'Data/Volume_Hand_Control_3.png'>\n",
    "<img src = 'Data/Volume_Hand_Control_4.png'>\n",
    "<img src = 'Data/Volume_Hand_Control_5.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
