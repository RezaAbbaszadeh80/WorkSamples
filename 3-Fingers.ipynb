{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# هدف : تشخیص انگشتان دست"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# وارد کردن کتابخانه های لازم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 23:17:52.571716: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-25 23:17:52.581161: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-25 23:17:52.594391: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-25 23:17:52.597557: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-25 23:17:52.607117: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-25 23:17:53.240841: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import mediapipe as mp\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# نادیده گرفتن هشدار های کم اهیمت"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from google.protobuf import message as pb_message\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='google.protobuf.symbol_database')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# تعریف رنگ ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv تعریف رنگ‌ها برای استفاده در ترسیمات البته  به صورت برعکس  چون \n",
    "red = (0, 0, 255)\n",
    "green = (0, 255, 0)\n",
    "blue = (255, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-  Mediapipe راه‌اندازی مدل تشخیص دست از"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724615274.354204    5052 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1724615274.357040    5217 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.1), renderer: Mesa Intel(R) Xe Graphics (TGL GT2)\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.7)\n",
    "\n",
    "# static_image_mode : برای پردازش ویدئو استفاده می‌شود (False) پیشفرض\n",
    "# True : مدل هر فریم را به‌عنوان یک تصویر مستقل در نظر می‌گیرد و دست‌ها را در هر فریم مجدداً شناسایی می‌کند. این حالت برای پردازش تصاویر ثابت مناسب است\n",
    "# False : اگر از یک ویدئو استفاده می‌کنید و می‌خواهید شناسایی دست‌ها در فریم‌های بعدی نیز انجام شود (بدون شناسایی مجدد در هر فریم)\n",
    "\n",
    "# max_num_hands : حداکثر تعداد شناسایی دست ها\n",
    "# 1 \n",
    "# 2 (پیشفرض)\n",
    "\n",
    "# min_detection_confidence: فقط دست‌هایی که با اطمینان از آن درصد  یا بیشتر شناسایی می‌شوند، در نظر گرفته خواهند شد\n",
    "#  برای شناسایی دست‌ها. مقادیر بین 0.0 تا 1.0 قابل قبول هستند (confidence)  حداقل اطمینان \n",
    "# مقدار پیش‌فرض: 0.5\n",
    "# مقدار بالاتر از 0.5 پیشنهاد می‌شود تا شناسایی دست‌ها دقیق‌تر باشد\n",
    "\n",
    "# min_tracking_confidence : دست‌ها بعد از شناسایی اولیه مقادیر بین 0.0 تا 1.0 قابل قبول هستند (tracking) حداقل اطمینان برای دنبال‌کردن \n",
    "# مقدار پیش‌فرض: 0.5\n",
    "# اگر نیاز دارید دست‌ها با اطمینان بیشتری در طول ویدئو دنبال شوند، این مقدار را افزایش دهید"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Mediapipe راه‌اندازی ابزارهای ترسیم از"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Data/mediapipe.png' width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# حلقه برای استفاده از تصاویر وبکم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1724615274.370755    5209 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1724615274.391774    5205 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# راه‌اندازی وبکم\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# تابع برای محاسبه فاصله بین دو نقطه\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.linalg.norm(np.array(point1) - np.array(point2))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # # RGB به BGR \n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # روی هر فریم MediaPipe پردازش تصویر با \n",
    "    # تعیین می شود x,y,z است که موقعیت آن‌ها بر اساس مختصات (landmarks) یک لیست از دست‌های شناسایی‌شده در فریم فعلی تصویر یا ویدیو را برمی‌گرداند. هر دست در این لیست شامل نقاط کلیدی\n",
    "    results = hands.process(frame_rgb)\n",
    "    \n",
    "    # اگر حداقل یک دست شناسایی شده باشد\n",
    "    if results.multi_hand_landmarks: \n",
    "        for id, hand_landmarks in enumerate(results.multi_hand_landmarks): \n",
    "\n",
    "            # لیست برای شمارش انگشتان باز\n",
    "            fingers = []\n",
    "\n",
    "            # بررسی جهت دست (راست یا چپ)\n",
    "            hand_label = results.multi_handedness[id].classification[0].label\n",
    "\n",
    "            # بررسی انگشت شست (نقاط ۲، ۳ و ۴)\n",
    "            thumb_tip = hand_landmarks.landmark[4]  # نوک انگشت شست\n",
    "            thumb_ip = hand_landmarks.landmark[3]   # بند وسط انگشت شست\n",
    "            thumb_mcp = hand_landmarks.landmark[2]  # بند پایه انگشت شست\n",
    "            index_mcp = hand_landmarks.landmark[7]  # بند وسط انگشت اشاره\n",
    "\n",
    "            # محاسبه فاصله نوک شست با وسط بند انگشت اشاره برای مشت کردن\n",
    "            thumb_index_distance = calculate_distance((thumb_tip.x, thumb_tip.y), (index_mcp.x, index_mcp.y))\n",
    "\n",
    "            # بررسی اینکه نوک انگشت شست نسبت به بند پایه و وسط انگشت در دست راست و چپ کجاست\n",
    "            if (hand_label == 'Right' and thumb_tip.x < thumb_mcp.x and thumb_index_distance > 0.1) or \\\n",
    "               (hand_label == 'Left' and thumb_tip.x > thumb_mcp.x and thumb_index_distance > 0.1):\n",
    "                fingers.append(1)\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "\n",
    "            # بررسی سایر انگشتان (۸، ۱۲، ۱۶، ۲۰)\n",
    "            for i in [8, 12, 16, 20]:\n",
    "                finger_tip = hand_landmarks.landmark[i]\n",
    "                finger_dip = hand_landmarks.landmark[i - 2]\n",
    "\n",
    "                if finger_tip.y < finger_dip.y:  # نوک انگشت بالاتر از بند نزدیک‌تر به کف دست\n",
    "                    fingers.append(1)\n",
    "                else:\n",
    "                    fingers.append(0)\n",
    "\n",
    "            # نمایش تعداد انگشتان باز\n",
    "            cv2.putText(frame, f'Hand {hand_label} Fingers: {sum(fingers)}', (10, 75 + id * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, blue, 2)\n",
    "            \n",
    "            # رسم نقاط کلیدی و اتصالات\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # نمایش تصویر\n",
    "    cv2.imshow('Hand Tracking', frame)\n",
    "\n",
    "    # به‌دست آوردن زمان کنونی\n",
    "    current_time = datetime.now()\n",
    "    current_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    k = cv2.waitKey(1) & 0xFF \n",
    "    if k==27:    # برای خروج Esc کلید \n",
    "        break\n",
    "    \n",
    "    elif k== ord('q'): # q یا دکمه \n",
    "        break\n",
    "\n",
    "    elif k == ord('s'):\n",
    "        filename = f'Data/captured_image_{current_time}.jpg'\n",
    "        cv2.imwrite(filename,frame)\n",
    "        print(f\"Image saved as {filename}\")\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# نمایش نتیجه"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Data/captured_image_2024-08-24 13:22:48.jpg'>\n",
    "<img src = 'Data/captured_image_2024-08-24 13:22:54.jpg'>\n",
    "<img src = 'Data/captured_image_2024-08-24 13:22:57.jpg'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
